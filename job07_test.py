import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPool1D, GRU, Dropout, Dense
import numpy as np
from keras.callbacks import EarlyStopping

# =============================
# ğŸ“Š 1. ë°ì´í„° ë¡œë“œ
# =============================

X_train = np.load('C:/workspace/Star_rating_review/Star_rating_review/crawling_data/review_data_X_train_max_129_wordsize_15845.npy', allow_pickle=True)
X_test = np.load('C:/workspace/Star_rating_review/Star_rating_review/crawling_data/review_data_X_test_max_129_wordsize_15845.npy', allow_pickle=True)
Y_train = np.load('C:/workspace/Star_rating_review/Star_rating_review/crawling_data/review_data_Y_train_max_129_wordsize_15845.npy', allow_pickle=True)
Y_test = np.load('C:/workspace/Star_rating_review/Star_rating_review/crawling_data/review_data_Y_test_max_129_wordsize_15845.npy', allow_pickle=True)

# ì›-í•« ì¸ì½”ë”© â†’ ì´ì§„ ë ˆì´ë¸” ë³€í™˜
Y_train = np.argmax(Y_train, axis=1)
Y_test = np.argmax(Y_test, axis=1)

print(X_train.shape, Y_train.shape)  # í•™ìŠµ ë°ì´í„° í¬ê¸° í™•ì¸
print(X_test.shape, Y_test.shape)  # í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° í™•ì¸

# =============================
# ğŸ› ï¸ 2. ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ ì •ì˜
# =============================

model = Sequential()

model.add(Embedding(input_dim=15845, output_dim=300))
model.add(Conv1D(64, kernel_size=5, padding='same', activation='relu'))
model.add(MaxPool1D(pool_size=1))

model.add(GRU(512, activation='tanh', return_sequences=True))
model.add(Dropout(0.3))
model.add(GRU(256, activation='tanh', return_sequences=True))
model.add(Dropout(0.3))
model.add(GRU(128, activation='tanh', return_sequences=True))
model.add(Dropout(0.3))
model.add(GRU(64, activation='tanh'))
model.add(Dropout(0.3))

model.add(Dense(1, activation='sigmoid'))

model.build(input_shape=(None, 129))
model.summary()

# =============================
# ğŸš¦ 3. í•™ìŠµ ì„¤ì • ë° ì‹¤í–‰
# =============================

early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

fit_hist = model.fit(X_train, Y_train, batch_size=128, epochs=30,
                     validation_data=(X_test, Y_test), callbacks=[early_stopping])

# =============================
# ğŸ“Š 4. ëª¨ë¸ í‰ê°€ ë° ì €ì¥
# =============================

score = model.evaluate(X_test, Y_test, verbose=0)
print('Test Loss:', score[0])
print('Test Accuracy:', score[1])

model.save('./models/review_data_binary_classification_model_{:.2f}.h5'.format(score[1]))

# =============================
# ğŸ“ˆ 5. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
# =============================

plt.plot(fit_hist.history['accuracy'], label='accuracy')
plt.plot(fit_hist.history['val_accuracy'], label='val_accuracy')
plt.legend()
plt.show()

plt.plot(fit_hist.history['loss'], label='loss')
plt.plot(fit_hist.history['val_loss'], label='val_loss')
plt.legend()
plt.show()
